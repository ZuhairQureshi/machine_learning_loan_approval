{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93209db4",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1b800c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all relevant packages\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4a8c8a",
   "metadata": {},
   "source": [
    "## Mapping and Updating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed347244",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('loan_approval_dataset.csv')\n",
    "data = raw_data.copy()\n",
    "\n",
    "data[' loan_status'] = data[' loan_status'].map({' Approved': 1, ' Rejected': 0})\n",
    "data[' education'] = data[' education'].map({' Graduate': 1, ' Not Graduate': 0})\n",
    "data[' self_employed'] = data[' self_employed'].map({' Yes': 1, ' No': 0})\n",
    "\n",
    "data.to_csv('loan_updated_data.csv', header = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3504ea3c",
   "metadata": {},
   "source": [
    "## Create Inputs and Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e003b98a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., ..., 0., 1., 1.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_csv_data = np.loadtxt('loan_updated_data.csv', delimiter = ',')\n",
    "all_unscaled_inputs = raw_csv_data[:, 1:-1]\n",
    "all_targets = raw_csv_data[:, -1]\n",
    "all_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "338781b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_indices = np.arange(all_unscaled_inputs.shape[0])\n",
    "np.random.shuffle(shuffle_indices)\n",
    "\n",
    "all_unscaled_inputs = all_unscaled_inputs[shuffle_indices]\n",
    "all_targets = all_targets[shuffle_indices]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7814c9ce",
   "metadata": {},
   "source": [
    "## Balancing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6d87d825",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_zero_targets = 4269 - int(np.sum(all_targets))\n",
    "\n",
    "one_targets_count = 0\n",
    "indices_to_remove = []\n",
    "\n",
    "for i in range(all_targets.shape[0]):\n",
    "    \n",
    "    if all_targets[i] == 1:\n",
    "        one_targets_count += 1\n",
    "        \n",
    "        if one_targets_count > num_zero_targets:\n",
    "            indices_to_remove.append(i)\n",
    "\n",
    "unscaled_updated_inputs = np.delete(all_unscaled_inputs, indices_to_remove, axis = 0)\n",
    "updated_targets = np.delete(all_targets, indices_to_remove, axis = 0)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53dc3a5b",
   "metadata": {},
   "source": [
    "## Standardize Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e465c406",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_inputs = preprocessing.scale(unscaled_updated_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bb9d4f",
   "metadata": {},
   "source": [
    "## Shuffle Once More"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ab97734",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_indices = np.arange(scaled_inputs.shape[0])\n",
    "np.random.shuffle(shuffle_indices)\n",
    "\n",
    "scaled_shuffled_inputs = scaled_inputs[shuffle_indices]\n",
    "shuffled_targets = updated_targets[shuffle_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27bef9a",
   "metadata": {},
   "source": [
    "## Splitting into Training, Validation, and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8c9fd9a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1289.0 2580 0.4996124031007752\n",
      "169.0 322 0.5248447204968945\n",
      "155.0 322 0.4813664596273292\n"
     ]
    }
   ],
   "source": [
    "sample_count = scaled_shuffled_inputs.shape[0]\n",
    "\n",
    "training_count = int(sample_count * 0.8)\n",
    "validation_count = int(sample_count * 0.1)\n",
    "test_count = int(sample_count * 0.1)\n",
    "\n",
    "training_inputs = scaled_shuffled_inputs[:training_count]\n",
    "training_targets = shuffled_targets[:training_count]\n",
    "\n",
    "validation_inputs = scaled_shuffled_inputs[training_count: training_count + validation_count]\n",
    "validation_targets = shuffled_targets[training_count: training_count + validation_count]\n",
    "\n",
    "test_inputs = scaled_shuffled_inputs[training_count+validation_count:]\n",
    "test_targets = shuffled_targets[training_count + validation_count:]\n",
    "\n",
    "\n",
    "print(np.sum(training_targets), training_count, np.sum(training_targets) / training_count)\n",
    "print(np.sum(validation_targets), validation_count, np.sum(validation_targets) / validation_count)\n",
    "print(np.sum(test_targets), test_count, np.sum(test_targets) / test_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59be8e81",
   "metadata": {},
   "source": [
    "## Move data to an external npz file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d273ed6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('Training Data', inputs= training_inputs, targets = training_targets)\n",
    "np.savez('Validation Data', inputs = validation_inputs, targets = validation_targets)\n",
    "np.savez('Testing Data', inputs = test_inputs, targets = test_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96b0103",
   "metadata": {},
   "source": [
    "## Create final input and target variables for training / verifying / testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b094cceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nausheen\\AppData\\Local\\Temp\\ipykernel_13788\\1697069938.py:3: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  inputs_for_training, targets_for_training = npz['inputs'].astype(np.float), npz['targets'].astype(np.int)\n",
      "C:\\Users\\Nausheen\\AppData\\Local\\Temp\\ipykernel_13788\\1697069938.py:3: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  inputs_for_training, targets_for_training = npz['inputs'].astype(np.float), npz['targets'].astype(np.int)\n",
      "C:\\Users\\Nausheen\\AppData\\Local\\Temp\\ipykernel_13788\\1697069938.py:7: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  inputs_for_validation, targets_for_validation = npz['inputs'].astype(np.float), npz['targets'].astype(np.int)\n",
      "C:\\Users\\Nausheen\\AppData\\Local\\Temp\\ipykernel_13788\\1697069938.py:7: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  inputs_for_validation, targets_for_validation = npz['inputs'].astype(np.float), npz['targets'].astype(np.int)\n",
      "C:\\Users\\Nausheen\\AppData\\Local\\Temp\\ipykernel_13788\\1697069938.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  inputs_for_testing, targets_for_testing = npz['inputs'].astype(np.float), npz['targets'].astype(np.int)\n",
      "C:\\Users\\Nausheen\\AppData\\Local\\Temp\\ipykernel_13788\\1697069938.py:11: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  inputs_for_testing, targets_for_testing = npz['inputs'].astype(np.float), npz['targets'].astype(np.int)\n"
     ]
    }
   ],
   "source": [
    "npz = np.load('Training Data.npz')\n",
    "\n",
    "inputs_for_training, targets_for_training = npz['inputs'].astype(np.float), npz['targets'].astype(np.int)\n",
    "\n",
    "npz = np.load('Validation Data.npz')\n",
    "\n",
    "inputs_for_validation, targets_for_validation = npz['inputs'].astype(np.float), npz['targets'].astype(np.int)\n",
    "\n",
    "npz = np.load('Testing Data.npz')\n",
    "\n",
    "inputs_for_testing, targets_for_testing = npz['inputs'].astype(np.float), npz['targets'].astype(np.int)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e8cb04e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "35/35 - 1s - loss: 0.4196 - accuracy: 0.8399 - val_loss: 0.2543 - val_accuracy: 0.9068 - 1s/epoch - 37ms/step\n",
      "Epoch 2/100\n",
      "35/35 - 0s - loss: 0.2238 - accuracy: 0.9186 - val_loss: 0.2246 - val_accuracy: 0.9130 - 124ms/epoch - 4ms/step\n",
      "Epoch 3/100\n",
      "35/35 - 0s - loss: 0.1967 - accuracy: 0.9318 - val_loss: 0.2243 - val_accuracy: 0.9161 - 129ms/epoch - 4ms/step\n",
      "Epoch 4/100\n",
      "35/35 - 0s - loss: 0.1824 - accuracy: 0.9345 - val_loss: 0.2237 - val_accuracy: 0.9130 - 137ms/epoch - 4ms/step\n",
      "Epoch 5/100\n",
      "35/35 - 0s - loss: 0.1718 - accuracy: 0.9364 - val_loss: 0.1985 - val_accuracy: 0.9224 - 180ms/epoch - 5ms/step\n",
      "Epoch 6/100\n",
      "35/35 - 0s - loss: 0.1603 - accuracy: 0.9450 - val_loss: 0.1966 - val_accuracy: 0.9193 - 148ms/epoch - 4ms/step\n",
      "Epoch 7/100\n",
      "35/35 - 0s - loss: 0.1496 - accuracy: 0.9488 - val_loss: 0.1952 - val_accuracy: 0.9193 - 150ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "35/35 - 0s - loss: 0.1437 - accuracy: 0.9523 - val_loss: 0.1906 - val_accuracy: 0.9317 - 147ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "35/35 - 0s - loss: 0.1346 - accuracy: 0.9492 - val_loss: 0.2031 - val_accuracy: 0.9193 - 204ms/epoch - 6ms/step\n",
      "Epoch 10/100\n",
      "35/35 - 0s - loss: 0.1331 - accuracy: 0.9535 - val_loss: 0.1837 - val_accuracy: 0.9286 - 195ms/epoch - 6ms/step\n",
      "Epoch 11/100\n",
      "35/35 - 0s - loss: 0.1208 - accuracy: 0.9620 - val_loss: 0.1873 - val_accuracy: 0.9379 - 162ms/epoch - 5ms/step\n",
      "Epoch 12/100\n",
      "35/35 - 0s - loss: 0.1157 - accuracy: 0.9647 - val_loss: 0.1869 - val_accuracy: 0.9379 - 162ms/epoch - 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18f5c333400>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = 11\n",
    "output_size = 2\n",
    "hidden_layer_size = 150\n",
    "BATCH_SIZE = 75\n",
    "EPOCHS = 100\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    \n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(output_size, activation = 'softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=2)\n",
    "\n",
    "model.fit(inputs_for_training,\n",
    "          targets_for_training,\n",
    "          batch_size = BATCH_SIZE,\n",
    "          epochs = EPOCHS,\n",
    "          callbacks = [early_stopping],\n",
    "          validation_data = (inputs_for_validation, targets_for_validation),\n",
    "          verbose = 2\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4a8ad7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1591 - accuracy: 0.9475\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(inputs_for_testing, targets_for_testing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "58842184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test loss: 0.16. Test accuracy: 94.75%\n"
     ]
    }
   ],
   "source": [
    "print('\\nTest loss: {0:.2f}. Test accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9e848d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python py3-TF2.0",
   "language": "python",
   "name": "py3-tf2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
